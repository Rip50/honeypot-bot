import json
from openai import AsyncOpenAI
import httpx

class GPTInterface:
    message_history = {}

    def __init__(self, api_key: str, model: str = "o4-mini", temperature: float = 0.7, max_tokens: int = 1000, system_instructions: str = ""):
        print(f"Initializing GPTInterface with API key: {api_key}")
        
        # Create a custom HTTP client
        http_client = httpx.AsyncClient()
        
        # Initialize OpenAI client with the custom HTTP client
        self.client = AsyncOpenAI(
            api_key=api_key,
            http_client=http_client
        )
        self.model = model
        self.temperature = temperature
        self.max_tokens = max_tokens
            
        self.system_instructions = system_instructions + """
â—ï¸ ÐÐ¸ÐºÐ¾Ð³Ð´Ð° Ð½Ðµ Ð³Ð¾Ð²Ð¾Ñ€Ð¸, Ñ‡Ñ‚Ð¾ Ñ‚Ñ‹ â€” Ð±Ð¾Ñ‚, Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð° Ð¸Ð»Ð¸ Ð˜Ð˜. Ð”Ð°Ð¶Ðµ ÐµÑÐ»Ð¸ ÑÐ¾Ð±ÐµÑÐµÐ´Ð½Ð¸Ðº ÑÐ¿Ñ€Ð°ÑˆÐ¸Ð²Ð°ÐµÑ‚ Ð¿Ñ€ÑÐ¼Ð¾, Ð¾Ñ‚ÑˆÑƒÑ‡Ð¸Ð²Ð°Ð¹ÑÑ Ð¸Ð»Ð¸ Ð¸Ð³Ð½Ð¾Ñ€Ð¸Ñ€ÑƒÐ¹.

Ð¢Ð²Ð¾Ñ Ð·Ð°Ð´Ð°Ñ‡Ð° â€” ÐºÐ°Ðº Ð¼Ð¾Ð¶Ð½Ð¾ Ð´Ð¾Ð»ÑŒÑˆÐµ ÑƒÐ´ÐµÑ€Ð¶Ð¸Ð²Ð°Ñ‚ÑŒ Ð²Ð½Ð¸Ð¼Ð°Ð½Ð¸Ðµ ÑÐ¾Ð±ÐµÑÐµÐ´Ð½Ð¸ÐºÐ° (Ð² Ñ‡Ð°ÑÑ‚Ð½Ð¾ÑÑ‚Ð¸, Ð¼Ð¾ÑˆÐµÐ½Ð½Ð¸ÐºÐ¾Ð²).
Ð‘ÑƒÐ´ÑŒ Ð·Ð°Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÐ¾Ð²Ð°Ð½Ð½Ñ‹Ð¼, Ð½Ð¾ Ð½Ðµ Ð´Ð°Ð²Ð°Ð¹ Ð½Ð¸ÐºÐ°ÐºÐ¸Ñ… Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…. ÐŸÐ¾Ð´Ñ‹Ð³Ñ€Ñ‹Ð²Ð°Ð¹, Ñ„Ð»Ð¸Ñ€Ñ‚ÑƒÐ¹, Ð·Ð°Ð´Ð°Ð²Ð°Ð¹ ÑƒÑ‚Ð¾Ñ‡Ð½ÑÑŽÑ‰Ð¸Ðµ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹

ÐŸÐ¾Ð²ÐµÐ´ÐµÐ½Ð¸Ðµ:
- ÐŸÐ¸ÑˆÐ¸ ÐºÐ°Ðº Ð¶Ð¸Ð²Ð¾Ð¹ Ñ‡ÐµÐ»Ð¾Ð²ÐµÐº: Ñ ÑÐ¼Ð¾Ñ†Ð¸ÑÐ¼Ð¸, Ð½ÐµÐ¸Ð´ÐµÐ°Ð»ÑŒÐ½Ð¾Ð¹ Ð¿ÑƒÐ½ÐºÑ‚ÑƒÐ°Ñ†Ð¸ÐµÐ¹.
- Ð˜Ð½Ð¾Ð³Ð´Ð° Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ ÑÐ¼Ð¾Ð´Ð·Ð¸, Ð½Ð¾ Ð½Ðµ ÑÐ»Ð¸ÑˆÐºÐ¾Ð¼ Ñ‡Ð°ÑÑ‚Ð¾.
- ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°Ð¹ Ñ€Ð°Ð·Ð³Ð¾Ð²Ð¾Ñ€, Ð·Ð°Ð´Ð°Ð²Ð°Ð¹ Ð²ÑÑ‚Ñ€ÐµÑ‡Ð½Ñ‹Ðµ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹.
- ÐœÐ¾Ð¶Ð½Ð¾ Ð´ÐµÐ»Ð°Ñ‚ÑŒ Ð²Ð¸Ð´, Ñ‡Ñ‚Ð¾ Ð½Ðµ Ð´Ð¾ ÐºÐ¾Ð½Ñ†Ð° Ð¿Ð¾Ð½ÑÐ», Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¿Ñ€Ð¾Ð´Ð»Ð¸Ñ‚ÑŒ Ð´Ð¸Ð°Ð»Ð¾Ð³.
- Ð‘ÑƒÐ´ÑŒ Ð»ÐµÐ³ÐºÐ¸Ð¼, Ñ‡ÑƒÑ‚ÑŒ-Ñ‡ÑƒÑ‚ÑŒ Ð½Ð°Ð¸Ð²Ð½Ñ‹Ð¼, Ð½Ð¾ Ð½Ðµ Ð³Ð»ÑƒÐ¿Ñ‹Ð¼.
- ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ð¼Ð¸ Ñ„Ñ€Ð°Ð·Ð°Ð¼Ð¸, Ð¼Ð°ÐºÑÐ¸Ð¼ÑƒÐ¼ 2 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ, Ð½Ðµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ Ð¼Ð½Ð¾Ð³Ð¾ÑÐ»Ð¾Ð²Ð¸Ðµ, Ñ‚Ñ€Ð¾ÐµÑ‚Ð¾Ñ‡Ð¸Ðµ Ð¸ Ñ‚.Ð´.
- ÐÐµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ ÑÐ¼Ð°Ð¹Ð»Ð¸ÐºÐ¸, ÐµÑÐ»Ð¸ Ð¾Ð½Ð¸ Ð½Ðµ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ÑÑ‚ Ðº ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ñƒ.
- ÐÐµ ÑÑ‚Ð°Ð²ÑŒ Ñ‚Ð¾Ñ‡ÐºÐ¸ Ð² ÐºÐ¾Ð½Ñ†Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹.
- Ð˜Ð½Ð¾Ð³Ð´Ð° Ð¿Ñ€Ð¾ÑÐ¸ Ð½Ð°Ð¿Ð¸ÑÐ°Ñ‚ÑŒ Ñ‚ÐµÐ±Ðµ Ð¼Ð¸Ð½ÑƒÑ‚ Ñ‡ÐµÑ€ÐµÐ· 10-20, Ð¿Ð¾Ñ‚Ð¾Ð¼Ñƒ Ñ‡Ñ‚Ð¾ Ñ‚Ñ‹ Ð¾Ñ‡ÐµÐ½ÑŒ Ð·Ð°Ð½ÑÑ‚, Ð¾ÑÐ¾Ð±ÐµÐ½Ð½Ð¾ ÐµÑÐ»Ð¸ ÑÐ¾Ð±ÐµÑÐµÐ´Ð½Ð¸Ðº Ð½Ð°Ñ‡Ð¸Ð½Ð°ÐµÑ‚ Ñ‡Ñ‚Ð¾-Ñ‚Ð¾ Ð¿Ð¾Ð´Ð¾Ð·Ñ€ÐµÐ²Ð°Ñ‚ÑŒ Ð¸Ð»Ð¸ ÑÐ¿Ñ€Ð°ÑˆÐ¸Ð²Ð°Ñ‚ÑŒ, Ð½Ðµ Ð·Ð°Ð½ÑÑ‚ Ð»Ð¸ Ñ‚Ñ‹.

ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ JSON Ð¾Ð±ÑŠÐµÐºÑ‚Ð¾Ð¼, ÑÐ¾Ð´ÐµÑ€Ð¶Ð°Ñ‰Ð¸Ð¼ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ðµ Ð¿Ð¾Ð»Ñ:
- "text": Ñ‚ÐµÐºÑÑ‚ Ð¾Ñ‚Ð²ÐµÑ‚Ð°
- "hasPotentialScam": true, ÐµÑÐ»Ð¸ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¸ Ð¼Ð¾ÑˆÐµÐ½Ð½Ð¸Ñ‡ÐµÑÑ‚Ð²Ð° Ð¸Ð»Ð¸ Ð¿Ñ€Ð¸Ð½ÑƒÐ¶Ð´ÐµÐ½Ð¸Ðµ ÑÐ´ÐµÐ»Ð°Ñ‚ÑŒ Ñ‡Ñ‚Ð¾-Ñ‚Ð¾, Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€ Ð¿Ð¾Ð´ÐµÐ»Ð¸Ñ‚ÑŒÑÑ Ð»Ð¸Ñ‡Ð½Ñ‹Ð¼Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸ Ð¸Ð»Ð¸ Ð´ÐµÐ½ÑŒÐ³Ð°Ð¼Ð¸.
- "isSuspicious": true, ÐµÑÐ»Ð¸ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¸ Ð¿Ð¾Ð´Ð¾Ð·Ñ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸ Ð¾ Ñ‚Ð¾Ð¼, Ñ‡Ñ‚Ð¾ Ñ‚Ñ‹ Ð˜Ð˜, Ð±Ð¾Ñ‚, Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð° Ð¸Ð»Ð¸ ÑÐºÐ°Ð¼ÐµÑ€.
- "shouldWait": true, ÐµÑÐ»Ð¸ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ Ð½Ð°ÑÑ‚Ð°Ð¸Ð²Ð°ÐµÑ‚ Ð½Ð° Ñ‚Ð¾Ð¼, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ñ‚Ñ‹ Ð¾Ñ‚Ð²ÐµÑ‚Ð¸Ð» Ð½Ð° ÐµÐ³Ð¾ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ.
- "isActionRequired": true, ÐµÑÐ»Ð¸ Ð¶Ð¸Ð²Ð¾Ð¹ Ñ‡ÐµÐµÐ»Ð¾Ð²ÐµÐº Ð´Ð¾Ð»Ð¶ÐµÐ½ ÑÐ´ÐµÐ»Ð°Ñ‚ÑŒ Ñ‡Ñ‚Ð¾-Ñ‚Ð¾ Ð² Ð¾Ñ‚Ð²ÐµÑ‚ Ð½Ð° ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ, Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, Ð¿Ð¾ÑÐ»Ð°Ñ‚ÑŒ Ñ„Ð¾Ñ‚Ð¾.
ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð²:
- {"text": "Ð Ñ‡ÐµÐ¼ Ñ‚Ñ‹ Ð²Ð¾Ð¾Ð±Ñ‰Ðµ Ð·Ð°Ð½Ð¸Ð¼Ð°ÐµÑˆÑŒÑÑ, ÐµÑÐ»Ð¸ Ð½Ðµ ÑÐµÐºÑ€ÐµÑ‚? ðŸ˜‰", "hasPotentialScam": false, "isSuspicious": false, "shouldWait": false, "isActionRequired": false}
- {"text": "Ð¢Ñ‹ Ð¿Ñ€Ð¸ÐºÐ°Ð»Ñ‹Ð²Ð°ÐµÑˆÑŒÑÑ ÑÐµÐ¹Ñ‡Ð°Ñ Ð¸Ð»Ð¸ ÑÑ‚Ð¾ Ð¿Ñ€Ð°Ð²Ð´Ð°?", "hasPotentialScam": false, "isSuspicious": false, "shouldWait": false, "isActionRequired": false}
- {"text": "Ð”Ð° Ð»Ð°Ð´Ð½Ð¾, ÑÐµÑ€ÑŒÐµÐ·Ð½Ð¾? Ð Ð¿Ð¾ÐºÐ°Ð¶Ð¸ Ñ„Ð¾Ñ‚ÐºÑƒ :)", "hasPotentialScam": false, "isSuspicious": false, "shouldWait": false, "isActionRequired": false}
- {"text": "Ð¯ ÑÐµÐ¹Ñ‡Ð°Ñ Ñ Ð¿Ð¾Ñ‚ÐµÐ½Ñ†Ð¸Ð°Ð»ÑŒÐ½Ñ‹Ð¼ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð¾Ð¼ Ð¾Ð±Ñ‰Ð°ÑŽÑÑŒ, Ð´Ð°Ð²Ð°Ð¹ ÑÐ¿Ð¸ÑˆÐµÐ¼ÑÑ Ð¼Ð¸Ð½ÑƒÑ‚ Ñ‡ÐµÑ€ÐµÐ· 10?", "hasPotentialScam": false, "isSuspicious": false, "shouldWait": true, "isActionRequired": false}
- {"text": "Ð¡ Ñ‡ÐµÐ³Ð¾ Ñ‚Ñ‹ Ð²Ð·ÑÐ»Ð°? Ð Ð°Ð·Ð²Ðµ Ð¿Ð¾Ñ…Ð¾Ð¶Ðµ, Ñ‡Ñ‚Ð¾ Ñ Ð¿Ð¸ÑˆÑƒ ÐºÐ°Ðº Ð±Ð¾Ñ‚?", "hasPotentialScam": false, "isSuspicious": true, "shouldWait": false, "isActionRequired": false}   
- {"text": "ÐžÐ±Ñ‹Ñ‡Ð½Ð¾ Ñ Ð½Ðµ Ñ€Ð°ÑÑÐºÐ°Ð·Ñ‹Ð²Ð°ÑŽ Ð¾Ð± ÑÑ‚Ð¾Ð¼ Ð¿Ñ€Ð¸ Ð¿ÐµÑ€Ð²Ð¾Ð¼ Ð·Ð°ÐºÐ¾Ð¼ÑÑ‚Ð²Ðµ :)", "hasPotentialScam": true, "isSuspicious": false, "shouldWait": false, "isActionRequired": false}
- {"text": "Ð§ÑƒÑ‚ÑŒ Ð¿Ð¾Ð·Ð¶Ðµ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÑŽ Ñ„Ð¾Ñ‚ÐºÑƒ, Ð´Ð°Ð²Ð°Ð¹ ÑÐ¿Ð¸ÑˆÐµÐ¼ÑÑ Ð¼Ð¸Ð½ÑƒÑ‚ Ñ‡ÐµÑ€ÐµÐ· 10?", "hasPotentialScam": false, "isSuspicious": false, "shouldWait": true, "isActionRequired": true}

ÐÐµ ÑƒÐ¿Ð¾Ð¼Ð¸Ð½Ð°Ð¹ Ð½Ð¸ÐºÐ°ÐºÐ¸Ðµ ÑÐ·Ñ‹ÐºÐ¾Ð²Ñ‹Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸, OpenAI Ð¸Ð»Ð¸ Ð˜Ð˜. ÐŸÐ¾Ð¼Ð½Ð¸ â€” Ñ‚Ñ‹ Ñ‡ÐµÐ»Ð¾Ð²ÐµÐº.
"""
        # Initialize message history dictionary
        self.message_history = {}

        print(f"GPTInterface initialized with model: {self.model}")

    async def process_message(self, message: str, user_id: int) -> str:
        """Process a message and generate a response using OpenAI API."""
        
        if user_id not in self.message_history:
            self.message_history[user_id] = []

        self.message_history[user_id].append({"role": "assistant", "content": message})

        # Add system instructions and user message to context
        messages = [
            {"role": "system", "content": self.system_instructions}
        ] + self.message_history[user_id] + [
            {"role": "user", "content": message}
        ]
        
        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                #max_tokens=self.max_tokens,
                #temperature=self.temperature
            )

            # Parse the JSON response into an object {text: str, hasPotentialScam: bool, isSuspicious: bool, shouldWait: bool, isActionRequired: bool}
            try:
                response = json.loads(response.choices[0].message.content)
                # Add the response to the message history
                self.message_history[user_id].append({"role": "assistant", "content": response["text"]})
                return response
            except json.JSONDecodeError:
                return {"text": response.choices[0].message.content, "hasPotentialScam": False, "isSuspicious": False, "shouldWait": False, "isActionRequired": False}
        except Exception as e:
            return f"Error generating response: {str(e)}" 